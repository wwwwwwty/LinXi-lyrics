
WORD2VEC_MODEL_PATH = 'data/word2vec.model'
WORD2VEC_SIZE = 200
WORD2VEC_MIN_COUNT = 1

ORIGINAL_DATA_PATH = 'data/original.txt'
PURE_DATA_PATH = 'data/pure.txt'
SPLIT_DATA_PATH = 'data/split_thulac.txt'
MODEL_PATH = 'model/20170728/'

NUM_EPOCH = 80
BATCH_SIZE = 32
SEQ_LENGTH = 20
EMBED_DIMENSION = 200
RNN_SIZE = 512
RNN_LAYER = 1
KEEP_PROB = 0.5
LEARNING_RATE = 0.001
GRID_CAP = 5.
SHOW_BATCHES = 1000


# result_date: 20170724
# Epoch  49 Batch  547/597   train_loss = 3.346
# Model Trained and Saved, cost 43964.578 second
# NUM_EPOCH = 50
# BATCH_SIZE = 64
# SEQ_LENGTH = 10
# EMBED_DIMENSION = 200
# RNN_SIZE = 512
# RNN_LAYER = 2
# KEEP_PROB = 0.75
# GRID_CAP = 3.
# LEARNING_RATE = 0.005


# result_date: 20170725
# Epoch  49 Batch  646/746   train_loss = 1.848
# Model Trained and Saved, cost 46107.139 second
# NUM_EPOCH = 50
# BATCH_SIZE = 64
# SEQ_LENGTH = 8
# EMBED_DIMENSION = 200
# RNN_SIZE = 512
# RNN_LAYER = 2
# KEEP_PROB = 0.75
# LEARNING_RATE = 0.001
# GRID_CAP = 5.
# SHOW_BATCHES = 200

# result_date: 20170726
# Epoch  49 Batch  924/1124   train_loss = 2.846
# Model Trained and Saved, cost 24680.385 second
# NUM_EPOCH = 50
# BATCH_SIZE = 64
# SEQ_LENGTH = 6
# EMBED_DIMENSION = 200
# RNN_SIZE = 256
# RNN_LAYER = 2
# KEEP_PROB = 0.75
# LEARNING_RATE = 0.001
# GRID_CAP = 5.
# SHOW_BATCHES = 200

# result_date: 20170727 (use thulac split)
# Epoch  49 Batch 1167/1217   train_loss = 3.124
# NUM_EPOCH = 50
# BATCH_SIZE = 64
# SEQ_LENGTH = 6
# EMBED_DIMENSION = 200
# RNN_SIZE = 256
# RNN_LAYER = 2
# KEEP_PROB = 0.75
# LEARNING_RATE = 0.001
# GRID_CAP = 5.
# SHOW_BATCHES = 200

# result_date: 20170728 (use thulac split)
# Epoch  49 Batch  408/608   train_loss = 3.536
# Model Trained and Saved, cost 44478.326 second
# NUM_EPOCH = 50
# BATCH_SIZE = 64
# SEQ_LENGTH = 12
# EMBED_DIMENSION = 200
# RNN_SIZE = 256
# RNN_LAYER = 3
# KEEP_PROB = 0.75
# LEARNING_RATE = 0.001
# GRID_CAP = 5.
# SHOW_BATCHES = 200

# result_date: 20170730 (use thulac split)
# Epoch  79 Batch  330/730   train_loss = 1.886
# Model Trained and Saved, cost 55232.382 second
# NUM_EPOCH = 80
# BATCH_SIZE = 32
# SEQ_LENGTH = 20
# EMBED_DIMENSION = 200
# RNN_SIZE = 512
# RNN_LAYER = 1
# KEEP_PROB = 0.5
# LEARNING_RATE = 0.001
# GRID_CAP = 5.
# SHOW_BATCHES = 1000
